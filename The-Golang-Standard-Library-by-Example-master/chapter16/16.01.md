# sync - 处理同步需求 #

协程概念：
1、协程通常称为coroutine，在golang中称为goroutine
2、协程本质上是一种用户态线程，轻量级线程，它不需要操作系统来进行抢占式调度，在实际实现中寄存在线程之中
3、协程系统开销极小，可有效提高单个线程的任务并发性，从而避免使用多线程。而且使用协程编程简单，结构清晰。缺点就是需要编程语言的支持，如果不支持，则需要用户在程序中自行实现调度器

golang是一门语言级别支持并发的程序语言。golang中使用go语句来开启一个新的协程。
goroutine是非常轻量的，除了给它分配栈空间，它所占用的内存空间是微乎其微的。
goroutine是golang中的轻量级线程实现，由go runtime管理

goroutine使用语法：
1、启动一个goroutine使用go关键字，go是golang中最重要的关键字，因此这个语言也是以这个关键字命名
2、在一个函数前加上go关键字调用，这次调用就会在一个新的goroutine中并发执行，开启goroutine的线程将继续执行。
3、当被go调用的函数返回时，这个goroutine也自动结束了。如果这个函数有返回值，那么这个返回值会被丢弃。
4、golang程序从main()函数开始执行，当main()函数返回时，程序结束且不等待其他goroutine结束。

并发执行：
1、如果在单核cpu情况下，golang所有的goroutine只能在一个线程里跑(相当于同步)。
2、如果当前goroutine不发生阻塞，它是不会让出cpu时间给其他goroutine，除非调用runtime.Gosched()主动让出时间片。(时间片到了以后，当前goroutinue还是会被强制让出CPU)
3、如果当前goroutine发生阻塞，它会主动让出cpu时间给其他goroutine执行。
4、golang的runtime包是goroutine的调度器，其中使用runtime.GOMAXPROCS(n)可以控制使用cpu核数。

并行执行:
1、默认情况下，golang是开启多核的
2、我们也可以告诉golang我们允许同时最多使用核数。runtime.GOMAXPROCS(n)


但当多个goroutine同时进行处理的时候，就会遇到比如同时抢占一个资源，某个goroutine等待另一个goroutine处理完某一个步骤之后才能继续的需求。
在golang的官方文档上，作者明确指出，golang并不希望依靠共享内存的方式进行进程的协同操作。而是希望通过管道channel的方式进行。
当然，golang也提供了共享内存，锁，等机制进行协同操作的包。sync包就是为了这个目的而出现的。

## 锁 ##

互斥锁概念：
互斥锁提供一个可以在同一时间，只让一个线程访问临界资源的的操作接口。互斥锁(Mutex)是个提供线程同步的基本锁。让上锁后，其他的线程如果想要锁上，那么会被阻塞，直到锁释放后。
如果，在锁释放后，有多个线程被阻塞，那么，所有的被阻塞的线程会被设为可执行状态。
第一个执行的线程，取得锁的控制权，上锁。其他的线程继续阻塞。

sync包中定义了Locker结构来代表锁。

```golang
type Locker interface {
    Lock()
    Unlock()
}
```
并且创造了两个结构来实现Locker接口：Mutex 和 RWMutex。

Mutex就是互斥锁，互斥锁代表着当数据被加锁了之后，除了加锁的程序，其他程序不能对数据进行读操作和写操作。
这个当然能解决并发程序对资源的操作。但是，效率上是个问题。当加锁后，其他程序要读取操作数据，就只能进行等待了。
这个时候就需要使用读写锁。




读写锁分为读锁和写锁，读数据的时候上读锁，写数据的时候上写锁。有写锁的时候，数据不可读不可写。有读锁的时候，数据可读，不可写。
互斥锁就不举例子，读写锁可以看下面的例子：

```golang
package main

import (
    "sync"
    "time"
)

var m *sync.RWMutex
var val = 0

func main() {
    m = new(sync.RWMutex)
    go read(1)
    go write(2)
    go read(3)
    time.Sleep(5 * time.Second)
}

func read(i int) {
    m.RLock()
    time.Sleep(1 * time.Second)
    println("val: ", val)
    time.Sleep(1 * time.Second)
    m.RUnlock()
}

func write(i int) {
	m.Lock()
    val = 10
	time.Sleep(1 * time.Second)
	m.Unlock()
}

返回：
val:  0
val:  10

```
但是如果我们把read中的RLock和RUnlock两个函数给注释了，就返回了:
```golang
val:  10
val:  10
```
这个就是由于读的时候没有加读锁，在准备读取val的时候，val被write函数进行修改了。

## 临时对象池 ##

当多个goroutine都需要创建同一个对象的时候，如果goroutine过多，可能导致对象的创建数目剧增。
而对象又是占用内存的，进而导致的就是内存回收的GC(垃圾回收机制 garbage collector)压力徒增。造成“并发大－占用内存大－GC缓慢－处理并发能力降低－并发更大”这样的恶性循环。
在这个时候，我们非常迫切需要有一个对象池，每个goroutine不再自己单独创建对象，而是从对象池中获取出一个对象（如果池中已经有的话）。
这就是sync.Pool出现的目的了。

sync.Pool的使用非常简单，提供两个方法:Get和Put 和一个初始化回调函数New。获取对象的时候如何在池里面找不到缓存的对象将会使用指定的New函数创建一个返回，如果没有New函数则返回nil

看下面这个例子（取自[gomemcache](https://github.com/bradfitz/gomemcache/blob/master/memcache/selector.go)）：
```golang
// keyBufPool returns []byte buffers for use by PickServer's call to
// crc32.ChecksumIEEE to avoid allocations. (but doesn't avoid the
// copies, which at least are bounded in size and small)
var keyBufPool = sync.Pool{
	New: func() interface{} {
		b := make([]byte, 256)
		return &b
	},
}

func (ss *ServerList) PickServer(key string) (net.Addr, error) {
	ss.mu.RLock()
	defer ss.mu.RUnlock()
	if len(ss.addrs) == 0 {
		return nil, ErrNoServers
	}
	if len(ss.addrs) == 1 {
		return ss.addrs[0], nil
	}
	bufp := keyBufPool.Get().(*[]byte)
	n := copy(*bufp, key)
	cs := crc32.ChecksumIEEE((*bufp)[:n])
	keyBufPool.Put(bufp)

	return ss.addrs[cs%uint32(len(ss.addrs))], nil
}
```

这是实际项目中的一个例子，这里使用keyBufPool的目的是为了让crc32.ChecksumIEEE所使用的[]bytes数组可以重复使用，减少GC的压力。

但是这里可能会有一个问题，我们没有看到Pool的手动回收函数。
那么是不是就意味着，如果我们的并发量不断增加，这个Pool的体积会不断变大，或者一直维持在很大的范围内呢？

答案是不会的，sync.Pool的回收是有的，它是在系统自动GC的时候，触发pool.go中的poolCleanup函数。

```golang
func poolCleanup() {
	for i, p := range allPools {
		allPools[i] = nil
		for i := 0; i < int(p.localSize); i++ {
			l := indexLocal(p.local, i)
			l.private = nil
			for j := range l.shared {
				l.shared[j] = nil
			}
			l.shared = nil
		}
		p.local = nil
		p.localSize = 0
	}
	allPools = []*Pool{}
}
```

这个函数会把Pool中所有goroutine创建的对象都进行销毁。

那这里另外一个问题也凸显出来了，很可能我上一步刚往pool中PUT一个对象之后，下一步GC触发，导致pool的GET函数获取不到PUT进去的对象。
这个时候，GET函数就会调用New函数，临时创建出一个对象，并存放到pool中。

根据以上结论，sync.Pool其实不适合用来做持久保存的对象池（比如连接池）。它更适合用来做临时对象池，目的是为了降低GC的压力。

连接池性能测试

```golang
package main

import (
    "sync"
    "testing"
)

var bytePool = sync.Pool{
    New: newPool,
}

func newPool() interface{} {
    b := make([]byte, 1024)
    return &b
}
func BenchmarkAlloc(b *testing.B) {
    for i := 0; i < b.N; i++ {
        obj := make([]byte, 1024)
        _ = obj
    }
}

func BenchmarkPool(b *testing.B) {
    for i := 0; i < b.N; i++ {
        obj := bytePool.Get().(*[]byte)
        _ = obj
        bytePool.Put(obj)
    }
}
```

文件目录下执行 `go test -bench . `

```
E:\MyGo\sync>go test -bench .
testing: warning: no tests to run
PASS
BenchmarkAlloc-4        50000000                39.3 ns/op
BenchmarkPool-4         50000000                25.4 ns/op
ok      _/E_/MyGo/sync  3.345s
```

通过性能测试可以清楚地看到，使用连接池消耗的CPU时间远远小于每次手动分配内存。

## Once ##

有的时候，我们多个goroutine都要过一个操作，但是这个操作我只希望被执行一次，这个时候Once就上场了。比如下面的例子:

```golang
package main

import (
    "fmt"
    "sync"
    "time"
)

func main() {
    var once sync.Once
    onceBody := func() {
        fmt.Println("Only once")
    }
    for i := 0; i < 10; i++ {
        go func() {
            once.Do(onceBody)
        }()
    }
    time.Sleep(3e9)
}

```
只会打出一次"Only once"。

## WaitGroup 和 Cond ##

一个goroutine需要等待一批goroutine执行完毕以后才继续执行，那么这种多线程等待的问题就可以使用WaitGroup了。golang中的同步是通过sync.WaitGroup来实现的．WaitGroup的功能：它实现了一个类似队列的结构，可以一直向队列中添加任务，当任务完成后便从队列中删除，如果队列中的任务没有完全完成，可以通过Wait()函数来出发阻塞，防止程序继续进行，直到所有的队列任务都完成为止．
WaitGroup的特点是Wait()可以用来阻塞直到队列中的所有任务都完成时才解除阻塞，而不需要sleep一个固定的时间来等待．但是其缺点是无法指定固定的goroutine数目．但是其缺点是无法指定固定的goroutine数目．可能通过使用channel解决此问题。

WaitGroup总共有三个方法：Add(delta int),Done(),Wait()。简单的说一下这三个方法的作用。

Add(n):添加或者减少等待goroutine的数量,n大于0表示添加n个等待goroutine的数量，小于0减少n个等待goroutine的数量
Done:相当于Add(-1)
Wait:执行阻塞，直到所有的WaitGroup数量变成0


```golang
package main

import (
    "fmt"
    "sync"
)

func main() {
    wp := new(sync.WaitGroup)
    wp.Add(10);

    for i := 0; i < 10; i++ {
        go func() {
            fmt.Println("done ", i)
            wp.Done()
        }()
    }

    wp.Wait()
    fmt.Println("wait end")
}
```


##Cond在Locker的基础上增加的一个消息通知的功能。但是它只能按照顺序去使一个goroutine解除阻塞。
Cond有三个方法：Wait，Signal，Broadcast。
Wait添加一个计数，也就是添加一个阻塞的goroutine。
Signal解除一个goroutine的阻塞，计数减一。随机解除一个goroutine的阻塞
Broadcast接触所有wait goroutine的阻塞。

还有个sync.Cond是用来控制某个条件下，goroutine进入等待时期，等待信号到来，然后重新启动。比如：

```golang
package main

import (
    "fmt"
    "sync"
    "time"
)

func main() {
    locker := new(sync.Mutex)
    cond := sync.NewCond(locker)
    done := false

    cond.L.Lock()

    go func() {
        time.Sleep(2e9)
        done = true
        cond.Signal()
    }()

    if (!done) {
        cond.Wait()
    }

    fmt.Println("now done is ", done);
}
```
这里当主goroutine进入cond.Wait的时候，就会进入等待，当从goroutine发出信号之后，主goroutine才会继续往下面走。

sync.Cond还有一个BroadCast方法，用来通知唤醒所有等待的gouroutine。
```golang

package main

import (
    "fmt"
    "sync"
    "time"
)

var locker = new(sync.Mutex)
var cond = sync.NewCond(locker)

func test(x int) {

    cond.L.Lock() // 获取锁
    cond.Wait()   // 等待通知  暂时阻塞
    fmt.Println(x)
    time.Sleep(time.Second * 1)
    cond.L.Unlock() // 释放锁，不释放的话将只会有一次输出
}
func main() {
    for i := 0; i < 40; i++ {
        go test(i)
    }
    fmt.Println("start all")
    cond.Broadcast() //  下发广播给所有等待的goroutine
    time.Sleep(time.Second * 60)
}

```
主gouroutine开启后，可以创建多个从gouroutine，从gouroutine获取锁后，进入cond.Wait状态，当主gouroutine执行完任务后，通过BroadCast广播信号。
处于cond.Wait状态的所有gouroutine收到信号后将全部被唤醒并往下执行。需要注意的是，从gouroutine执行完任务后，需要通过cond.L.Unlock释放锁， 否则其它被唤醒的gouroutine将没法继续执行。

由于各个Wait收到信号的时间是不确定的，因此每次的输出顺序也都是随机的。
# 导航 #

- [目录](/preface.md)
- 上一节：buildin
- 下一节：暂未确定
